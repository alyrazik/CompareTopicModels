import pandas as pd
import gensim
import time
import json
keywords = ['topic modeling', 'neural topic model', 'topic model', 'neural topic modelling']
documents_clusters = pd.Series(
    '0 3 2 1 3 1 3 2 0 2 0 1 3 0 0 3 3 3 2 0 2 1 0 0 2 3 1 3 3 2 1 3 2 2 1 0 2'
    '2 3 3 2 3 2 0 2 0 3 1 2 1 0 2 2 0 2 3 3 3 1 1 0 1 3 3 2 1 0 0 3 1 2 1 0 1'
    '1 2 3 3 3 2 3 3 1 3 3 0 3 0 2 1 2 2 3 3 1 3 3 2 3 2 3 1 1 1 3 3 3 1 2 2 2'
    '2 2 0 3 2 3 1 2 2 1 0 0 1 2 1 2 3 3 2 1 2 1 2 0 2 0 0 3 1 1 3 2 3 1 3 1 2'
    '2 1 1 2 0 2 3 2 2 2 3 3 1 1 3 0 3 1 1 0 0 3 0 3 3 2 3 1 2 3 0 1 0 0 2 2 0'
    '3 1 0 0 2 1 0 2 3 3 3 1 1 1 2 2 2 1 2 1 3 3 2 1 3 3 2 0 2 0 0 1 2 3 0 0 2'
    '2 2 3 1 1 2 0 1 1 0 2 3 0 3 2 3 0 3 0 2 1 2 1 1 0 2 3 3 1 3 0 1 0 2 1 1 2'
    '2 2 1 1 3 1 3 3 3 2 3 1 2 2 0 0 3 0 2 2 2 2 2 2 3 2 3 3 2 0 1 3 3 2 0 3 0'
    '3 3 1 3 0 3 2 0 3 3 1 1 2 2 2 0 1 0 1 3 3 3 0 3 2 2 1 3 1 3 0 3 1 1 2 2 0'
    '3 3 2 3 0 3 3 2 0 2 0 2 2 2 1 2 0 2 3 0 1 2 3 1 2 0 1 1 3 2 0 0 3 1 1 1 2'
    '2 2 1 1 1 1 2 2 2 2 1 3 0 0 0 1 2 3 0 2 0 1 3 2 0 1 2 0 3 2 2 1 2 3 2 2 1'
    '3 3 3 2 2 2 2 3 0 2 2 1 1 3 3 1 2 1 2 3 2 1 1 0 1 2 3 3 2 3 1 1 3 3 2 3 0'
    '2 0 3 2 3 3 3 3 1 3 3 2 3 2 1 3 0 1 0 1 1 1 3 3 0 2 2 1 3 1 3 1 3 3 3 1 1'
    '0 0 2 1 0 0 0 3 2 1 3 3 2 3 2 1 3 1 2 0 3 1 1 0 3 1 0 3 1 1 3 3 2 3 2 3 3'
    '3 2 3 3 2 3 3 1 1 3 2 3 2 1 3 3 3 2 1 1 1 3 3 3 2 3 2 3 2 3 2 2 2 2 0 2 2'
    '1 2 2 2 3 3 3 3 3 3 0 2 3 3 2 3 0 2 2 2 3 2 1 0 2 2 0 3 1 1 2 2 3 0 1 2 3'
    '1 1 2 0 1 1 1 2 0 2 3 2 1 3 3 3 3 0 3 3 1 2 3 1 2 0 3 3 3 0 1 0 1 0 1 0 2'
    '3 3 1 1 0 3 2 1 3 3 3 2 3 1 1 2 0 2 0 2 2 2 2 2 0 2 3 1 3 3 0 2 3 3 2 3 1'
    '3 3 1 3 1 1 2 2 2 2 2 3 0 3 2 1 0 3 2 2 1 3 0 1 2 1 3 0 1 3 1 3 3 0 2 1 0'
    '3 0 2 2 2 3 0 2 3 0 1 1 0 2 0 2 3 2 3 3 2 2 2 3 3 1 3 1 3 1 2 2 2 2 0 2 3'
    '2 0 2 1 1 2 3 0 1 2 2 1 0 2 2 3 1 0 0 1 2 0 3 1 1 3 3 0 0 1 1 0 3 1 2 0 2'
    '3 0 2 1 3 0 1 2 3 3 2 0 3 1 0 0 1 2 1 3 2 2 3 1 3 1 0 3 3 1 1 3 0 2 3 3 1'
    '1 3 0 3 0 2 3 3 2 1 3 1 3 2 0 3 2 0 0 2 3 1 3 0 3 1 2 2 3 0 2 3 2 3 1 2 2 2 3 1'.split())

centers = '-3.79510133e-06  4.82507570e-04  4.10179449e-05 -5.32759528e-05'
'-3.21219531e-04 -4.96166066e-04 -1.53881719e-04 -4.69068887e-04'
'-2.63355423e-04  5.27599097e-05 -1.73411030e-04  6.16009312e-05'
'1.81948794e-04  2.09393590e-04 -3.09011812e-04 -1.92772061e-04'
'5.88793170e-06 -4.35000373e-04 -2.56286010e-04 -1.62702016e-04'
'3.83364143e-04 -6.18849429e-05 -6.21745994e-04 -2.13095833e-04'
'-4.14481434e-04 -4.93517687e-04 -3.73306186e-04 -1.44459134e-04'
'3.77759762e-04 -2.49702878e-05  7.08492352e-05  1.42351162e-04'
'-2.21410633e-05  9.55604453e-05  2.22336737e-04  5.18173307e-04'
'-1.86322408e-04 -5.03198962e-04 -5.09478059e-04  2.90752954e-04'
'-2.88979451e-04 -2.70427338e-04 -3.15386216e-04 -2.47883014e-05'
'-3.55123380e-04 -4.08633463e-04 -2.78366920e-05 -1.98853579e-04'
'-4.42103076e-06 -2.76734823e-04  6.28003282e-05 -2.64293376e-04'
'7.39154562e-04 -1.19766307e-04  3.94231243e-04 -5.80047554e-04'
'-1.32202563e-04 -1.99840414e-04  2.59270326e-04  1.06598787e-04'
'9.93541347e-06  2.63282566e-04 -2.21058599e-04 -1.72553496e-04'
'-3.10744179e-04  2.29557220e-04  7.10248548e-05 -3.43071274e-04'
'1.69077118e-04  3.21308513e-04 -3.77411335e-05 -3.26374585e-04'
'-2.81451083e-04  2.95771739e-04  3.73573545e-04 -8.85328966e-07'
'5.15848331e-04 -2.21421091e-04 -3.97030512e-05  8.32856570e-06'
'5.26714783e-04 -2.35834323e-04 -5.40008008e-04  1.84490106e-04'
'4.96737227e-04 -1.93969859e-05 -1.58665491e-04 -3.83510956e-04'
'7.17237996e-04  1.95836161e-04  1.16789331e-05  3.56438793e-05'
'2.58934549e-04 -5.51247446e-05  2.74039018e-04  4.37341833e-04'
'2.49210229e-04  5.81456452e-06 -4.05781693e-04 -1.56447545e-04'
'-3.13821260e-04 -7.42761331e-05  5.31569300e-04  3.87163033e-05'
'-3.66935032e-04 -2.35845166e-05  2.87896485e-04  2.56892424e-04'
'8.35480582e-04  1.89865856e-05  1.19623729e-04  3.40793372e-04'
'-2.30766141e-04 -8.22103568e-05 -1.78733382e-04  7.21872009e-05'
'2.26014851e-04 -3.39304601e-05 -2.49845017e-04 -1.91059661e-04'
'-7.10740886e-05 -6.52644308e-05  5.70481682e-05  8.90307639e-05'
'5.58384131e-04 -2.47947009e-05 -6.02430686e-04  3.94368261e-05'
'1.06898875e-04 -1.15921420e-04  1.99477586e-04 -2.81210672e-04'
'1.63936675e-04 -7.87028022e-05 -4.63967269e-04  3.02040075e-06'
'-3.10378372e-04  1.21126472e-04  1.41423765e-04 -1.23367290e-04'
'-7.25367328e-05 -3.80712483e-04  6.32054534e-04 -3.92971983e-04'
'-3.76772305e-04  1.18247231e-04 -3.78889617e-04  5.42394252e-04'
'1.42256702e-04  1.33329297e-04'.split()


 # [ 2.02936769e-04  1.98839822e-04  5.03389220e-04  2.86935804e-06
 #   1.58315216e-04  2.19722527e-04 -1.47300774e-04  4.72256862e-04
 #  -3.22953909e-04  9.61014764e-05  9.47134690e-05  3.49312484e-04
 #   1.74666072e-05  1.16024256e-04 -3.68157001e-04 -2.44249437e-04
 #   2.36971661e-04 -6.37795920e-05  3.52232240e-04 -3.62185408e-04
 #  -4.13660894e-06  6.21179667e-04  1.41368607e-04 -1.00274407e-04
 #   2.94352472e-04  2.09937563e-04  8.09297985e-05  6.62508037e-05
 #  -4.52046778e-04  7.67552610e-05 -1.70467123e-04 -1.53540110e-04
 #  -2.22112246e-04  1.52079171e-04  2.72971900e-05 -3.11356185e-04
 #   5.36999978e-04  1.10721934e-04  3.89633105e-04  1.48275680e-04
 #  -2.66500860e-04  1.87887384e-04 -2.25007646e-05  4.05928848e-04
 #   3.57750565e-06 -4.20514704e-04 -2.24369074e-04  5.68950840e-07
 #   5.22373506e-04 -6.60519810e-04  1.81221018e-04  1.64367805e-04
 #  -3.06429046e-04 -8.01972389e-05 -7.82813915e-05 -1.06068440e-04
 #  -1.45249361e-04  1.03470146e-05  2.75128476e-04  7.86236240e-05
 #   1.83305135e-04 -7.33393607e-05 -9.45654435e-05 -6.01223514e-04
 #   5.58018755e-04  3.12723909e-04 -2.19247535e-04 -1.28008891e-04
 #   3.55921813e-04 -1.47941244e-04  8.72233269e-05 -2.99966640e-04
 #   1.58599171e-04 -5.48632517e-04 -1.36205896e-04  4.43802386e-04
 #   3.74121565e-04  7.27914682e-05 -4.94787308e-04  3.58029504e-04
 #   2.44056118e-04  2.80863286e-04  8.19821289e-05 -9.95126584e-05
 #  -4.99495492e-04  6.33759602e-04 -2.58862219e-04  1.19443644e-04
 #  -8.97458352e-05 -2.78511340e-04  8.00986115e-05 -4.81881183e-04
 #  -5.22208064e-05  1.26975717e-04 -3.61844879e-04 -1.43867542e-04
 #   2.79705643e-04  1.47081158e-04 -4.12065196e-05  8.47071257e-04
 #  -2.64543180e-04 -4.12435131e-04 -8.38781901e-04 -3.38171657e-04
 #   1.68329774e-04  2.65914276e-04 -1.14623720e-04 -5.71736331e-04
 #  -5.18773747e-04 -2.79042310e-04 -3.92754921e-04 -9.65309340e-05
 #   2.75395694e-04  1.86877948e-04  2.46316444e-04  3.19250442e-04
 #  -2.10710074e-05  5.89574693e-04  2.08719756e-04 -7.55021821e-05
 #   7.77008421e-04 -4.17749944e-04 -1.52008958e-04  3.40648681e-04
 #  -4.33309335e-04 -4.27370831e-04  1.69882278e-04 -7.71192308e-05
 #   2.15507540e-04 -6.86387813e-05 -1.36251669e-04  1.71939104e-04
 #   1.78647899e-04 -2.48152915e-04  1.77187129e-04  2.91359199e-04
 #   2.06270769e-04 -4.58484158e-04  6.81959256e-05  3.21613325e-04
 #  -1.00707450e-04  6.73814246e-05 -8.44228594e-04  4.45891343e-04
 #  -7.18271766e-05 -7.58450574e-05  4.82041005e-04  5.80027304e-04
 #  -1.39762269e-04 -1.29703847e-04],
 # [-2.03532280e-04 -2.96911412e-04 -2.70790410e-04  2.19165009e-04
 #  -9.04292509e-05  1.34326305e-05  4.94172293e-04 -3.56412514e-04
 #   3.50920615e-05  1.33784241e-04  4.23728929e-04  9.35059825e-05
 #  -1.08720120e-04 -2.43815012e-04  2.92190797e-04  7.23348381e-05
 #  -8.65816501e-05 -6.20418010e-06 -7.20554240e-05  2.52970563e-04
 #  -1.52380768e-04 -3.52921424e-04  2.20161532e-04  1.21602471e-05
 #  -4.19619580e-05 -2.41509141e-04  4.61026006e-04  3.68249332e-04
 #   2.79055647e-05  1.06933147e-05 -9.36058065e-05  1.73419016e-04
 #   1.72816494e-04  9.12915809e-05  1.80634621e-04  1.45303629e-04
 #  -1.30663325e-04  3.86297685e-04 -2.32849893e-04 -4.08952550e-04
 #  -2.26973549e-04  8.39664965e-05  2.71578093e-04 -2.38565599e-04
 #   5.12101254e-05 -3.14448896e-04  8.70431824e-05  2.22879247e-04
 #   5.27615582e-05 -1.62369624e-05 -3.24343728e-04 -1.47978968e-05
 #  -4.84415384e-04  5.00409098e-05 -5.23555000e-04  1.85294478e-04
 #   2.61449126e-04 -6.84244060e-05 -2.13552191e-04  1.95360793e-04
 #   4.17215906e-05 -1.18442886e-04  9.31098861e-05  4.74292586e-05
 #  -3.23951786e-04  1.67924150e-04 -2.04302473e-05  1.44917944e-04
 #  -3.68390540e-04 -7.08954097e-06 -1.32438799e-05  3.96304739e-04
 #   1.98410822e-05  1.01153553e-04 -1.14045101e-04  1.59449789e-04
 #  -3.35604053e-04  3.34362925e-05  3.82875977e-04  2.80786200e-04
 #  -3.36016095e-04  2.91847036e-04  6.03168645e-05 -6.56693316e-05
 #   3.80956462e-04 -4.31957948e-05 -3.86120824e-05  1.84749415e-04
 #  -2.38932323e-05  6.27990706e-05  2.89143034e-04 -2.20171775e-04
 #   1.13855601e-05  5.00924660e-05  1.17293886e-04 -3.25183867e-04
 #  -3.51552338e-04  3.55616075e-04  1.86800686e-04  3.84477692e-05
 #   3.66307364e-04 -1.77083105e-04  2.17531148e-04 -1.49278089e-04
 #  -2.98697450e-05 -3.14530935e-04  5.35962180e-05  3.29662022e-04
 #  -3.59116485e-04  2.68076911e-04 -1.01809998e-04 -3.45146322e-04
 #   2.55045035e-04 -2.62120516e-04  2.21957146e-04 -1.75495886e-04
 #   1.19211190e-04 -1.82951966e-04 -3.37241984e-04  1.48795411e-05
 #  -4.59556903e-04  9.95026308e-05  1.87354487e-04 -1.11524604e-04
 #   1.60807833e-04  3.44618037e-04 -1.44484221e-05  2.89802651e-04
 #   1.12261958e-04  1.12238694e-04  3.88481211e-05 -1.00303161e-06
 #  -4.92758809e-04  2.03225491e-04 -1.14345604e-04 -6.06925886e-04
 #   1.96059244e-04  2.85752278e-04 -6.18371382e-04  3.31566305e-04
 #   1.70979906e-04 -1.67398808e-04  3.83661253e-04  3.79678265e-04
 #   5.16634395e-04 -4.49925502e-04 -3.21844679e-04 -5.00004630e-04
 #   2.77078092e-04 -7.79381933e-05]
 # [ 1.14007619e-04 -1.01042029e-04  1.41459398e-04  1.76440994e-04
 #   2.49695890e-04 -1.20857955e-04 -7.54966703e-05  1.79939337e-04
 #   3.36102301e-04 -1.31985157e-04 -4.44907395e-04 -1.69140253e-04
 #   2.58759649e-04  1.15042711e-04  1.47566197e-04  5.12509521e-04
 #  -2.98063085e-04  1.23803302e-04  4.42758699e-05  1.80300426e-04
 #  -2.71271899e-04  1.24433113e-04 -2.43712254e-04  1.87961413e-04
 #   4.44081718e-04  2.69775112e-04 -1.49104185e-04 -1.79915313e-04
 #  -1.11983779e-04 -3.16355839e-04 -2.39398905e-04  1.99983749e-05
 #  -2.73405560e-04 -3.40036973e-05 -1.42186366e-05 -3.94529699e-04
 #   1.71749323e-05 -1.10083395e-04  3.94072268e-04  2.19127313e-04
 #   4.15338051e-04  2.72711668e-04  6.29718104e-05 -3.95515641e-05
 #   3.99844781e-04  7.92618502e-04  6.76668373e-05  1.79672610e-04
 #  -3.66147838e-04  2.56327800e-04  3.92709174e-05  2.98431366e-04
 #   3.58857496e-04  1.39778078e-04  5.03754444e-04  2.88333590e-04
 #  -1.77843155e-04  3.08655681e-04  1.77440152e-04 -2.27013930e-04
 #  -3.02474559e-04  7.65592056e-05  3.24664352e-04  4.02783655e-04
 #   2.27418039e-04 -4.31387457e-04 -7.08679661e-05 -1.26952822e-06
 #   8.72514597e-05 -9.20373974e-05  3.72244571e-04  3.60569758e-04
 #  -2.67141006e-05 -6.56546386e-05 -8.28702659e-05 -3.60531884e-04
 #  -4.97842579e-04 -9.32004818e-05  7.25241511e-05 -4.17069542e-04
 #   2.25316629e-05 -1.16447878e-04  3.32935769e-04  2.85066977e-04
 #  -4.77718718e-04 -3.29696271e-04  4.37175770e-04 -1.47766328e-04
 #  -5.10649507e-05  3.50332960e-05 -2.95764154e-04  5.40186567e-04
 #  -1.96241401e-04 -1.08165929e-04  7.29939036e-05  2.14081344e-04
 #  -1.73547454e-04 -3.86712265e-04 -3.88973135e-04 -6.63615298e-04
 #  -6.71629410e-07  8.86056064e-04  5.08454101e-04  3.57638165e-04
 #   9.49575571e-05  4.21928250e-04 -4.85293524e-04 -2.82928392e-04
 #   2.10868175e-05 -1.77155420e-04  6.48110972e-04  2.51829828e-04
 #   9.88598968e-05  2.03340612e-04 -2.99387914e-04 -4.67662895e-04
 #  -4.50519566e-04 -7.28664705e-05  2.20050197e-04  1.43628237e-04
 #  -5.38312702e-05  2.62675065e-04 -3.37760466e-05 -6.20233248e-04
 #  -3.33795910e-04 -1.45997574e-04  5.81584921e-04 -1.94219949e-04
 #  -2.07259823e-05 -2.39171892e-04  1.77779286e-04  4.61559482e-04
 #   2.21233598e-04 -1.78425844e-04  1.32853061e-04  2.83038582e-04
 #   1.58775376e-04 -6.58354207e-05  4.60741358e-05 -7.11361500e-04
 #  -2.97355539e-04 -1.19785864e-04 -2.46668772e-04 -3.40542574e-04
 #  -1.80079029e-04  1.50312513e-05  3.33441559e-04 -8.79002806e-05
 #   1.03288337e-05 -1.01403482e-04]]

DataPath = '//home//mohamed//PycharmProjects//TopicModel//arXiv_metadata//arxiv-metadata-oai-snapshot.json'
# Read file that contains metadata about papers (no paper text)


def get_metadata():
    """define a generator function since file is too big to handle in memory all at once"""
    with open(DataPath, 'r') as file:
        for line in file:
            yield line


def main():
    metadata = get_metadata()  # now metadata is an iterable

    titles = []
    authors = []
    abstracts = []
    update_dates = []

    print("Reading documents...")
    t1 = time.time()
    for paper in metadata:
        paper_dict = json.loads(paper)
        if 'cs.' in paper_dict['categories']:
            abstract = paper_dict['abstract'].lower()
            if any(phrase in abstract for phrase in keywords):
                titles.append(paper_dict['title'])
                authors.append(paper_dict['authors'])
                abstracts.append(abstract)
                update_dates.append(paper_dict['update_date'])
    t = time.time()-t1
    print('Reading time is ', t)

    df = pd.DataFrame(zip(titles, authors, abstracts, update_dates),
                      columns=['title', 'author', 'abstract', 'update_date'])

    print("Number of documents: ", df.shape[0])
    df['clusters'] = documents_clusters

    print(df.head())
    df.to_csv('//home//mohamed//PycharmProjects//TopicModel//bin//clustered_papers.csv', encoding='utf-8')

    dictionary = gensim.corpora.Dictionary(df['abstract'].apply(lambda x: x.split()))
    corpus = [
        gensim.models.doc2vec.TaggedDocument(dictionary.doc2bow(doc), [i]) for i, doc in enumerate(df['abstract'])
    ]

    # model
    model = gensim.models.word2vec.Word2Vec(vector_size=150, min_count=2, epochs=40)
    model.build_vocab(corpus)
    # print(f"Word 'neural' appeared {model.wv.get_vecattr('neural', 'count')} times in the training corpus.")
    model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)
    # vectors = df['abstract'].apply(
    #     lambda x: model.infer_vector(x)
    # ).tolist()

    topic1 = pd.Series(centers).apply(lambda x: float(x)).tolist()
    print(model.predict_output_word(topic1))


if __name__ == '__main__':
    main()
